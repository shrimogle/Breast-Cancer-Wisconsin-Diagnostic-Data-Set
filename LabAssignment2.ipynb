{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzSqR0BtqIzJZrsNkgN7y3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrimogle/Breast-Cancer-Wisconsin-Diagnostic-Data-Set/blob/main/LabAssignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhacK4iFmdjS"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "Please read this first\n",
        "\n",
        "I am working on diabetes dataset to make 4 Notebook so that i can show importance of Machine Learning and Statistics together.\n",
        "\n",
        "In multivariate analysis, i will not focus on distribution of data, this has been discussed in Notebook 1 (Univariate Statistical Analysis). Please find the notebook below ==>\n",
        "\n",
        "Univariate Statistical Analysis\n",
        "\n",
        "The notebook you are reading is second notebook in this series.\n",
        "\n",
        "Here is third notebook which gives you an understanding of how to make inference about population from population.\n",
        "\n",
        "Inferential Statistics on Diabetes\n",
        "\n",
        "Read Forth Notebook also :) ==>\n",
        "\n",
        "Predective Modeeling\n",
        "Happy Learning\n",
        "What is “multivariate”?\n",
        "\n",
        "Multivariate data analysis is a set of statistical models that examine patterns in multidimensional data by considering, at once, several data variables. It is an expansion of bivariate data analysis, which considers only two variables in its models. As multivariate models consider more variables, they can examine more complex phenomena and find data patterns that more accurately represent the real world.\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "df = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\n",
        "df.head()\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "I am conveting Outcome as Diab for Diabetic Patients and Non-Diab for Non Diabetic Patients. Also i will be renaming column name DiabetesPedigreeFunction to DPF.\n",
        "\n",
        "df.Outcome = df.Outcome.replace({0:'Non-Diab',1:'Diab'})\n",
        "df.DiabetesPedigreeFunction = df.rename({'DiabetesPedigreeFunction':'DPF'},inplace = True,axis =1)\n",
        "df.head()\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "df.dtypes\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "df.shape\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "df.info()\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "df.describe().T\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "Basic Summary\n",
        "\n",
        "Data is related to healthcare Industry having 768 observations with 9 variable. Target variable is Outcome. It looks like there is no missing value, and boolean, float , integers are different datatypes available. Well descriptive analysis shows that variable Glucose, BoodPressure,SckinThickness, Insulin and BMI have minimum value 0 which does not make any sense, these values are either missing or outliers, But i am not going to alter them so that i can see actual statistics of Data. I can see in Pregnancies column, minimum is 0 (May be this is sign for no pregnancy) which is considerable, But maximum month of pregnancy is 17 which does not make any sense. Variance among different predictor variable is varying at large scale , Scaling data will be helpful for Predective modelling.\n",
        "Pairplot\n",
        "\n",
        "Let us take a closer look at data by doing a quick visualization\n",
        "\n",
        "plt.figure(dpi=120)\n",
        "sns.pairplot(df)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "Summary ==>\n",
        "\n",
        "Well, Pregnancies, Insulin, DBF and Age having skewed distribution. We know most of the machine learning models uses assumpton of normality so these variables might need to be scaled, But we may consider the assumption to be true according Central Limit Theorem that if number of observation is large we can consider the distribution to be normal or bell shaped. Removing Outliers may also help us to achieve normal distribution of that variable.\n",
        "\n",
        "It looks like Glucose, BP and BMI variables have some outliers.\n",
        "\n",
        "Variables are not correlated strongly with each other. I will plot a correlation matrix later.\n",
        "Let us Plot pairplot according to outcome\n",
        "\n",
        "plt.figure(dpi = 120)\n",
        "sns.pairplot(df,hue = 'Outcome',palette = 'plasma')\n",
        "plt.legend(['Non Diabetic','Diabetic'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "Summary ==>\n",
        "\n",
        "We can clearly see that data points are not seperable linearly according to Outcome. Distribution of variables are normal, In some variables they are skewed to right due to Outliers. Treating Outliers may help to get rid of them. Because data points are spread non linear, Fitting tree based models might help us to get better accuracy or SVC with Non Linear Dicision Boundry.\n",
        "Correlation\n",
        "\n",
        "plt.figure(dpi = 120,figsize= (5,4))\n",
        "mask = np.triu(np.ones_like(df.corr(),dtype = bool))\n",
        "sns.heatmap(df.corr(),mask = mask, fmt = \".2f\",annot=True,lw=1,cmap = 'plasma')\n",
        "plt.yticks(rotation = 0)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "Nice, Variables are not much associated linearly.\n",
        "Jointplots\n",
        "\n",
        "plt.figure(dpi = 100, figsize = (5,4))\n",
        "print(\"Joint plot of Glucose with Other Variables ==> \\n\")\n",
        "for i in  df.columns:\n",
        "    if i != 'Glucose' and i != 'Outcome':\n",
        "        print(f\"Correlation between Glucose and {i} ==> \",df.corr().loc['Glucose'][i])\n",
        "        sns.jointplot(x='Glucose',y=i,data=df,kind = 'regression',color = 'purple')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "Insights\n",
        "\n",
        "Glucose shows positive weak linear association with other variable in given dataset. That means On increasing Glucose level in patients, Other variables will also increase. Weak linear association is good, so that we can escape out from Multicollinearity effect in Predective Modelling.\n",
        "\n",
        "col = list(df.columns)\n",
        "idx = col.index('BloodPressure')\n",
        "\n",
        "plt.figure(dpi = 100, figsize = (5,4))\n",
        "print(\"Joint plot of BloodPressure with Other Variables ==> \\n\")\n",
        "for i in  range(idx+1,len(col)-1):\n",
        "    print(f\"Correlation between BloodPressure and {col[i]} ==> \",df.corr().loc['BloodPressure'][col[i]])\n",
        "    sns.jointplot(x='BloodPressure',y=col[i],data=df,kind = 'regression',color = 'green')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "Insights\n",
        "\n",
        "BloodPressure shows positive weak linear association with other variable in given dataset. That means On increasing BP level in patients, Other variables will also increase.\n",
        "\n",
        "col = list(df.columns)\n",
        "idx = col.index('SkinThickness')\n",
        "\n",
        "plt.figure(dpi = 100, figsize = (5,4))\n",
        "print(\"Joint plot of SkinThickness with Other Variables ==> \\n\")\n",
        "for i in  range(idx+1,len(col)-1):\n",
        "    print(f\"Correlation between SkinThickness and {col[i]} ==> \",df.corr().loc['SkinThickness'][col[i]])\n",
        "    sns.jointplot(x='SkinThickness',y=col[i],data=df,kind = 'regression',color = 'blue')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "Insights\n",
        "\n",
        "SkinThickness shows positive weak linear association with other variable in given dataset ,(Except with Age) . That means On increasing SkinThickness in patients, Other variables will also increase.SkinThickness with Age show a weak negative correlation, that means on increasing SkinThickness , Age must decrease.\n",
        "\n",
        "col = list(df.columns)\n",
        "idx = col.index('Insulin')\n",
        "\n",
        "plt.figure(dpi = 100, figsize = (5,4))\n",
        "print(\"Joint plot of Insulin with Other Variables ==> \\n\")\n",
        "for i in  range(idx+1,len(col)-1):\n",
        "    print(f\"Correlation between Insulin and {col[i]} ==> \",df.corr().loc['Insulin'][col[i]])\n",
        "    sns.jointplot(x='Insulin',y=col[i],data=df,kind = 'regression',color = 'green')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "Insights\n",
        "\n",
        "Insulin shows positive weak linear association with other variable in given dataset ,(Except with Age) . That means On increasing Insulin level in patients, Other variables will also increase.Insulin with Age show a weak negative correlation, that means on increasing SkinThickness , Age must decrease.\n",
        "\n",
        "col = list(df.columns)\n",
        "idx = col.index('BMI')\n",
        "\n",
        "plt.figure(dpi = 100, figsize = (5,4))\n",
        "print(\"Joint plot of BMI with Other Variables ==> \\n\")\n",
        "for i in  range(idx+1,len(col)-1):\n",
        "    print(f\"Correlation between BMI and {col[i]} ==> \",df.corr().loc['BMI'][col[i]])\n",
        "    sns.jointplot(x='BMI',y=col[i],data=df,kind = 'regression',color = 'green')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "Insights\n",
        "\n",
        "BMI shows positive weak linear association with other variable in given dataset. That means On increasing BMI level in patients, Other variables will also increase.\n",
        "\n",
        "col = list(df.columns)\n",
        "idx = col.index('DPF')\n",
        "\n",
        "plt.figure(dpi = 100, figsize = (5,4))\n",
        "print(\"Joint plot of DPF with Other Variables ==> \\n\")\n",
        "for i in  range(idx+1,len(col)-1):\n",
        "    print(f\"Correlation between DPF and {col[i]} ==> \",df.corr().loc['DPF'][col[i]])\n",
        "    sns.jointplot(x='DPF',y=col[i],data=df,kind = 'regression',color = 'red')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "Insights\n",
        "\n",
        "DPF shows positive weak linear association with other variable in given dataset. That means On increasing DPF in patients, Other variables will also increase.\n",
        "Outcome\n",
        "\n",
        "Let us see, how data is behaving with Target variable using PCA\n",
        "\n",
        "x= df.iloc[:,:-1].values\n",
        "y= df.iloc[:,-1].values\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(x)\n",
        "\n",
        "x_new = pca.transform(x)\n",
        "\n",
        "xs = x[:,0]\n",
        "ys = x[:,1]\n",
        "\n",
        "plt.figure(dpi=100)\n",
        "sns.scatterplot(x=xs,y=ys,hue=y).set_title('Dependency of Data with Outcome')\n",
        "plt.xlabel('PCA Feature 1')\n",
        "plt.ylabel('PCA Feature 2')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "** Fitting a linea model to this data will not lead to better accuracy because data points are not linearly seperable, May be in higher dimension we can some more details in my 4th Notebook. For now fitting a tree based model or neural network will help us to achieve more accuracy**\n",
        "Thank you for reading !! Please upvote if you like this notebook :)\n"
      ]
    }
  ]
}